<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Statistical Analysis in R | HARP Team R Training</title>
  <style>
    body {
      font-family: 'Arial', sans-serif;
      line-height: 1.6;
      margin: 0;
      padding: 0;
      color: #333;
      background-color: #f8f9fa;
    }
    header {
      background-color: #2c3e50;
      color: white;
      padding: 20px 0;
      text-align: center;
    }
    .container {
      max-width: 1000px;
      margin: 0 auto;
      padding: 20px;
    }
    h1, h2, h3, h4 {
      color: #2c3e50;
    }
    pre {
      background-color: #f5f5f5;
      border-left: 4px solid #3498db;
      padding: 15px;
      margin: 20px 0;
      overflow-x: auto;
      border-radius: 4px;
    }
    code {
      font-family: 'Consolas', 'Monaco', monospace;
    }
    .topic-nav {
      background-color: white;
      border-radius: 8px;
      padding: 15px;
      margin-bottom: 20px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    .topic-nav ul {
      list-style: none;
      padding: 0;
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
    }
    .topic-nav li {
      margin-right: 10px; /* Kept for potential spacing adjustments */
    }
    .section {
      background-color: white;
      padding: 25px;
      margin-bottom: 25px;
      border-radius: 8px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    .exercise {
      background-color: #e8f4fc;
      padding: 20px;
      border-radius: 8px;
      margin: 25px 0;
    }
    .exercise h3 {
      margin-top: 0;
      color: #2980b9;
    }
    button {
      background-color: #3498db;
      color: white;
      border: none;
      padding: 10px 15px;
      border-radius: 4px;
      cursor: pointer;
      margin-top: 10px; /* Added margin */
    }
    button:hover {
      background-color: #2980b9;
    }
    .result {
      margin-top: 15px;
      padding: 10px;
      border-radius: 4px;
      display: none;
    }
    .correct {
      background-color: #d4edda;
      color: #155724;
    }
    .incorrect {
      background-color: #f8d7da;
      color: #721c24;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
    }
    th, td {
      border: 1px solid #ddd;
      padding: 10px;
      text-align: left;
    }
    th {
      background-color: #f2f2f2;
    }
    img {
      max-width: 100%;
      height: auto;
      display: block;
      margin: 20px auto;
    }
    a {
      color: #3498db;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    .home-link {
      display: inline-block;
      margin-bottom: 20px;
    }
    .quiz-option {
      margin: 10px 0;
    }
    .code-input {
      width: 95%; /* Adjusted width */
      height: 80px; /* Adjusted height */
      font-family: 'Consolas', 'Monaco', monospace;
      padding: 10px;
      margin-bottom: 10px;
      border: 1px solid #ccc;
      border-radius: 4px;
    }
     .resources {
      margin-top: 30px;
      border-top: 1px solid #eee;
      padding-top: 15px;
    }
    footer {
      background-color: #2c3e50;
      color: white;
      text-align: center;
      padding: 20px 0;
      margin-top: 50px;
    }
  </style>
</head>
<body>
  <!-- Assuming auth.js handles authentication/redirection if needed -->
  <script src="auth.js"></script>

  <header>
    <div class="container">
      <h1>Statistical Analysis in R</h1>
      <p>Performing statistical tests and modeling (Intermediate)</p>
    </div>
  </header>

  <div class="container">
    <a href="index.html" class="home-link">‚Üê Back to Course Index</a>

    <div class="topic-nav section">
      <h3>In this module:</h3>
      <ul>
        <li><a href="#descriptive-stats">Descriptive Statistics</a></li>
        <li><a href="#correlation">Correlation Analysis</a></li>
        <li><a href="#hypothesis-testing">Hypothesis Testing</a></li>
        <li><a href="#linear-regression">Linear Regression</a></li>
        <!-- Add more links as sections are added -->
      </ul>
    </div>

    <div class="section" id="descriptive-stats">
      <h2>Descriptive Statistics</h2>
      <p>Descriptive statistics summarize and describe the main features of a dataset, providing a quantitative overview.</p>

      <h4>Basic Summary Statistics</h4>
      <p>The `summary()` function provides a quick overview for numeric variables (min, 1st quartile, median, mean, 3rd quartile, max) and frequency counts for factors/characters.</p>
      <pre><code># Load example data
data(iris) # Famous dataset about iris flowers

# Summary of the entire dataset
summary(iris)

# Summary of a specific column
summary(iris$Sepal.Length)</code></pre>

      <h4>Measures of Central Tendency</h4>
      <p>Describe the center of your data.</p>
      <pre><code># Assuming 'data' is your data frame and 'column_name' is the column of interest
# Replace with your actual data and column names

# Mean (average)
mean(iris$Sepal.Length, na.rm = TRUE) # na.rm = TRUE ignores missing values (NA)

# Median (middle value when sorted)
median(iris$Sepal.Length, na.rm = TRUE)

# Mode (most frequent value) - R doesn't have a built-in function, requires custom code or package
# Example using a simple custom function:
get_mode <- function(v) {
  uniqv <- unique(v[!is.na(v)]) # Get unique non-NA values
  uniqv[which.max(tabulate(match(v, uniqv)))]
}
get_mode(iris$Species) # Output: "setosa" (or whichever is most frequent)</code></pre>

      <h4>Measures of Dispersion (Variability)</h4>
      <p>Describe how spread out your data is.</p>
      <pre><code># Standard Deviation (average distance from the mean)
sd(iris$Sepal.Length, na.rm = TRUE)

# Variance (average squared distance from the mean)
var(iris$Sepal.Length, na.rm = TRUE)

# Range (difference between max and min)
range_vals <- range(iris$Sepal.Length, na.rm = TRUE) # Returns min and max
diff(range_vals) # Calculates the difference

# Minimum and Maximum
min(iris$Sepal.Length, na.rm = TRUE)
max(iris$Sepal.Length, na.rm = TRUE)

# Quantiles (including Quartiles and Percentiles)
# Quartiles divide data into 4 equal parts
quantile(iris$Sepal.Length, na.rm = TRUE) # Default: 0%, 25%, 50%, 75%, 100%

# Specific quantiles/percentiles
quantile(iris$Sepal.Length, probs = c(0.1, 0.5, 0.9), na.rm = TRUE) # 10th, 50th, 90th percentiles

# Interquartile Range (IQR): Difference between 75th and 25th percentiles
IQR(iris$Sepal.Length, na.rm = TRUE)</code></pre>

      <h4>Frequency Distributions</h4>
      <p>Show how often different values or categories occur.</p>
      <pre><code># Frequency table for a categorical variable (Factor)
table(iris$Species)

# Frequency table for a numeric variable (often less useful unless rounded/binned)
# table(iris$Sepal.Length) # Shows count for each unique length

# Proportions table (frequencies as percentages)
prop.table(table(iris$Species))

# Cross-tabulation (frequency table for two categorical variables)
# Example: Create a categorical size variable first
iris$Size <- ifelse(iris$Sepal.Length < median(iris$Sepal.Length), "Small", "Large")
table(iris$Species, iris$Size)</code></pre>

      <h4>Grouped Summaries (using dplyr)</h4>
      <p>Often, you want summaries calculated for different groups within your data. The `dplyr` package is excellent for this.</p>
      <pre><code>library(dplyr) # Make sure dplyr is installed and loaded

iris %>%
  group_by(Species) %>%
  summarize(
    Avg.Sepal.Length = mean(Sepal.Length, na.rm = TRUE),
    Median.Petal.Width = median(Petal.Width, na.rm = TRUE),
    SD.Sepal.Width = sd(Sepal.Width, na.rm = TRUE),
    N = n() # Count number of observations in each group
  )</code></pre>

      <div class="exercise">
        <h3>Exercise: Descriptive Statistics</h3>
        <p>Using the built-in `mtcars` dataset:</p>
        <p>1. Calculate the mean, median, and standard deviation of the miles per gallon (`mpg`) column.</p>
        <p>2. Find the 10th and 90th percentiles for the horsepower (`hp`) column.</p>
        <p>3. Create a frequency table for the number of cylinders (`cyl`).</p>
        <p>4. Using `dplyr`, calculate the average `mpg` and average weight (`wt`) for each cylinder group (`cyl`).</p>
        <button onclick="toggleSolution('sol_desc_stats')">Show/Hide Solution Code</button>
        <div class="result" id="sol_desc_stats" style="display: none; background-color: #f5f5f5;">
            <pre><code># Load the dataset (already available in R)
data(mtcars)

# 1. Mean, Median, SD for mpg
mean_mpg <- mean(mtcars$mpg, na.rm = TRUE)
median_mpg <- median(mtcars$mpg, na.rm = TRUE)
sd_mpg <- sd(mtcars$mpg, na.rm = TRUE)
print(paste("Mean MPG:", round(mean_mpg, 2)))
print(paste("Median MPG:", round(median_mpg, 2)))
print(paste("SD MPG:", round(sd_mpg, 2)))

# 2. Percentiles for hp
hp_percentiles <- quantile(mtcars$hp, probs = c(0.1, 0.9), na.rm = TRUE)
print("Horsepower Percentiles (10th, 90th):")
print(hp_percentiles)

# 3. Frequency table for cyl
cyl_table <- table(mtcars$cyl)
print("Cylinder Frequency Table:")
print(cyl_table)

# 4. Grouped summary using dplyr
library(dplyr)
grouped_summary <- mtcars %>%
  group_by(cyl) %>%
  summarize(
    Average_MPG = mean(mpg, na.rm = TRUE),
    Average_Weight = mean(wt, na.rm = TRUE),
    Count = n()
  )
print("Summary by Number of Cylinders:")
print(grouped_summary)</code></pre>
        </div>
      </div>
    </div>

    <div class="section" id="correlation">
      <h2>Correlation Analysis</h2>
      <p>Correlation measures the strength and direction of the linear relationship between two numeric variables. The correlation coefficient ranges from -1 to +1:</p>
      <ul>
        <li>+1: Perfect positive linear relationship</li>
        <li>-1: Perfect negative linear relationship</li>
        <li>0: No linear relationship</li>
      </ul>
      <p><strong>Important:</strong> Correlation does not imply causation!</p>

      <h4>Calculating Correlation Coefficients</h4>
      <p>The `cor()` function calculates the correlation. Key methods include:</p>
      <ul>
        <li><strong>Pearson (default):</strong> Measures linear association. Assumes data is approximately normally distributed and the relationship is linear. Sensitive to outliers.</li>
        <li><strong>Spearman:</strong> Measures monotonic association (whether one variable tends to increase as the other increases, not necessarily linearly). Rank-based, less sensitive to outliers, doesn't assume normality.</li>
        <li><strong>Kendall:</strong> Also measures monotonic association using ranks. Often used for smaller datasets or data with many tied ranks.</li>
      </ul>
      <pre><code># Using iris dataset (selecting only numeric columns for correlation)
iris_numeric <- iris[, 1:4] # Select Sepal.Length, Sepal.Width, Petal.Length, Petal.Width

# Pearson correlation between two variables
cor(iris_numeric$Sepal.Length, iris_numeric$Petal.Length, method = "pearson")
# Or simply: cor(iris$Sepal.Length, iris$Petal.Length)

# Spearman correlation
cor(iris_numeric$Sepal.Length, iris_numeric$Petal.Length, method = "spearman")

# Kendall correlation
cor(iris_numeric$Sepal.Length, iris_numeric$Petal.Length, method = "kendall")

# Handling missing values in correlation
# Option 1: use = "complete.obs" (removes rows with any NA in the pair)
# cor(data$x, data$y, use = "complete.obs")
# Option 2: use = "pairwise.complete.obs" (uses all available pairs for each calculation)
# cor(data_frame_with_NAs, use = "pairwise.complete.obs")</code></pre>

      <h4>Correlation Matrix</h4>
      <p>Calculate correlations between multiple variables simultaneously.</p>
      <pre><code># Correlation matrix for the numeric iris columns
cor_matrix <- cor(iris_numeric, method = "pearson", use = "complete.obs")
print(round(cor_matrix, 2)) # Round for readability</code></pre>

      <h4>Visualizing Correlations</h4>
      <p>Scatter plots are essential for visualizing the relationship between two variables. Correlation matrices can be visualized using packages like `corrplot` or `ggcorrplot`.</p>
      <pre><code># Basic scatter plot
plot(iris$Petal.Length, iris$Petal.Width,
     main = "Petal Length vs. Petal Width",
     xlab = "Petal Length (cm)",
     ylab = "Petal Width (cm)",
     pch = 19) # pch changes the plotting symbol

# Correlation matrix visualization (requires installing packages)
# install.packages("corrplot")
library(corrplot)
corrplot(cor_matrix, method = "circle") # Many methods available: "number", "color", etc.

# install.packages("ggcorrplot")
library(ggcorrplot)
ggcorrplot(cor_matrix, hc.order = TRUE, type = "lower",
           lab = TRUE, lab_size = 3, method="circle",
           colors = c("blue", "white", "red"), title="Iris Correlation Matrix")</code></pre>

      <div class="exercise">
        <h3>Exercise: Correlation</h3>
        <p>Using the `mtcars` dataset:</p>
        <p>1. Calculate the Pearson correlation coefficient between `mpg` (miles per gallon) and `wt` (weight).</p>
        <p>2. Calculate the Spearman correlation coefficient between `hp` (horsepower) and `qsec` (1/4 mile time).</p>
        <p>3. Generate a correlation matrix for the variables `mpg`, `wt`, `hp`, and `disp` (displacement).</p>
        <p>4. Create a scatter plot of `mpg` vs `wt`.</p>
        <button onclick="toggleSolution('sol_correlation')">Show/Hide Solution Code</button>
        <div class="result" id="sol_correlation" style="display: none; background-color: #f5f5f5;">
            <pre><code>data(mtcars)

# 1. Pearson correlation mpg vs wt
pearson_mpg_wt <- cor(mtcars$mpg, mtcars$wt, method = "pearson")
print(paste("Pearson correlation (mpg vs wt):", round(pearson_mpg_wt, 3)))

# 2. Spearman correlation hp vs qsec
spearman_hp_qsec <- cor(mtcars$hp, mtcars$qsec, method = "spearman")
print(paste("Spearman correlation (hp vs qsec):", round(spearman_hp_qsec, 3)))

# 3. Correlation matrix
selected_vars <- mtcars[, c("mpg", "wt", "hp", "disp")]
cor_matrix_mtcars <- cor(selected_vars, use = "complete.obs")
print("Correlation Matrix (mpg, wt, hp, disp):")
print(round(cor_matrix_mtcars, 2))

# 4. Scatter plot mpg vs wt
plot(mtcars$wt, mtcars$mpg,
     main = "MPG vs. Weight",
     xlab = "Weight (1000 lbs)",
     ylab = "Miles per Gallon (MPG)",
     pch = 19, col = "blue")
# Add a regression line (optional)
abline(lm(mpg ~ wt, data = mtcars), col = "red", lwd = 2)</code></pre>
        </div>
      </div>
    </div>

    <div class="section" id="hypothesis-testing">
      <h2>Hypothesis Testing</h2>
      <p>Hypothesis testing is a formal procedure for investigating ideas about the world using statistics. It involves setting up a null hypothesis (H‚ÇÄ, often stating no effect or no difference) and an alternative hypothesis (H‚ÇÅ, stating an effect or difference). We use sample data to determine if there's enough evidence to reject the null hypothesis.</p>
      <p>Key concepts:</p>
      <ul>
        <li><strong>p-value:</strong> The probability of observing data as extreme as, or more extreme than, what was actually observed, *assuming the null hypothesis is true*.</li>
        <li><strong>Significance Level (Œ±):</strong> A threshold (commonly 0.05) used to make a decision. If p-value < Œ±, we reject H‚ÇÄ.</li>
        <li><strong>Rejecting H‚ÇÄ:</strong> Suggests evidence supports the alternative hypothesis.</li>
        <li><strong>Failing to Reject H‚ÇÄ:</strong> Means there isn't enough evidence to support the alternative hypothesis (it doesn't prove H‚ÇÄ is true).</li>
      </ul>

      <h4>t-Tests</h4>
      <p>Used to compare means.</p>
      <ul>
        <li><strong>One-Sample t-Test:</strong> Compares the mean of a single sample to a known population mean (or a hypothesized value).
          <br><em>H‚ÇÄ: Sample mean = hypothesized mean (Œº‚ÇÄ)</em></li>
        <li><strong>Two-Sample t-Test (Independent):</strong> Compares the means of two independent groups. Assumes normality and equal variances (by default, Welch's correction is used if variances are unequal).
          <br><em>H‚ÇÄ: Mean of group 1 = Mean of group 2</em></li>
        <li><strong>Paired t-Test:</strong> Compares the means of the same subjects under two different conditions (e.g., before and after treatment).
          <br><em>H‚ÇÄ: Mean difference between pairs = 0</em></li>
      </ul>
      <pre><code># Example data (replace with actual data)
group1_scores <- rnorm(30, mean = 50, sd = 10)
group2_scores <- rnorm(35, mean = 55, sd = 12)
before_scores <- rnorm(25, mean = 100, sd = 15)
after_scores <- before_scores + rnorm(25, mean = 5, sd = 5) # Simulate improvement

# One-sample t-test (Test if group1 mean is different from 48)
t_result_one <- t.test(group1_scores, mu = 48)
print(t_result_one)
# Interpretation: Look at the p-value. If < 0.05, reject H0.
# Look at the confidence interval for the mean. Does it contain 48?

# Two-sample t-test (Test if group1 and group2 means are different)
t_result_two <- t.test(group1_scores, group2_scores) # Assumes unequal variances (Welch test)
# To assume equal variances: t.test(group1_scores, group2_scores, var.equal = TRUE)
print(t_result_two)
# Interpretation: Look at p-value. If < 0.05, reject H0 (means are likely different).

# Paired t-test (Test if there's a difference between before and after)
t_result_paired <- t.test(after_scores, before_scores, paired = TRUE)
# Or equivalently: t.test(after_scores - before_scores, mu = 0)
print(t_result_paired)
# Interpretation: Look at p-value. If < 0.05, reject H0 (likely a significant difference).</code></pre>
      <p><strong>Formula Notation for Two-Sample Test:</strong> You can also use formula notation, especially if your data is in a "long" format with a grouping variable.</p>
      <pre><code># Example using iris data
# Test if Sepal.Length differs between setosa and versicolor
setosa_versicolor <- subset(iris, Species %in% c("setosa", "versicolor"))
t.test(Sepal.Length ~ Species, data = setosa_versicolor)</code></pre>

      <h4>Chi-Square Test (œá¬≤)</h4>
      <p>Used for analyzing categorical data.</p>
      <ul>
        <li><strong>Test for Independence:</strong> Determines if there is a significant association between two categorical variables.
          <br><em>H‚ÇÄ: The two variables are independent.</em></li>
        <li><strong>Goodness-of-Fit Test:</strong> Determines if sample proportions match hypothesized population proportions.
          <br><em>H‚ÇÄ: Sample proportions = Hypothesized proportions.</em></li>
      </ul>
      <pre><code># Test for Independence (using the mtcars dataset's cyl and am columns)
# Convert to factors if they aren't already
mtcars$cyl_factor <- factor(mtcars$cyl)
mtcars$am_factor <- factor(mtcars$am, labels = c("Automatic", "Manual"))

contingency_table <- table(mtcars$cyl_factor, mtcars$am_factor)
print(contingency_table)

chisq_result <- chisq.test(contingency_table)
print(chisq_result)
# Interpretation: Look at p-value. If < 0.05, reject H0 (variables are likely associated).
# Warning about expected counts might appear if counts are low (< 5).

# Goodness-of-Fit Test (Example: Test if cylinder distribution matches 20%, 30%, 50%)
observed_counts <- table(mtcars$cyl_factor)
hypothesized_props <- c(0.2, 0.3, 0.5) # For 4, 6, 8 cylinders respectively
chisq_gof_result <- chisq.test(observed_counts, p = hypothesized_props)
print(chisq_gof_result)
# Interpretation: Look at p-value. If < 0.05, reject H0 (sample distribution differs from hypothesized).</code></pre>

      <h4>ANOVA (Analysis of Variance)</h4>
      <p>Compares the means of three or more groups.</p>
      <ul>
        <li><strong>One-Way ANOVA:</strong> One categorical independent variable (factor) and one continuous dependent variable.
          <br><em>H‚ÇÄ: The means of all groups are equal.</em></li>
      </ul>
      <pre><code># One-Way ANOVA using iris data (Compare Sepal.Length across the 3 Species)
aov_result <- aov(Sepal.Length ~ Species, data = iris)
summary(aov_result) # The summary shows the F-statistic and p-value
# Interpretation: Look at the p-value ('Pr(>F)'). If < 0.05, reject H0 (at least one group mean is different).

# If ANOVA is significant, use post-hoc tests to see which specific groups differ
tukey_result <- TukeyHSD(aov_result)
print(tukey_result)
plot(tukey_result) # Visualize differences</code></pre>

      <h4>Normality Tests</h4>
      <p>Many statistical tests (like t-tests, ANOVA) assume data is normally distributed. The Shapiro-Wilk test is a common way to check this.</p>
      <p><em>H‚ÇÄ: The data is normally distributed.</em></p>
      <pre><code># Shapiro-Wilk test on iris Sepal.Length
shapiro.test(iris$Sepal.Length)
# Interpretation: If p-value < 0.05, reject H0 (data is likely not normally distributed).

# Check normality within groups (important for ANOVA/t-tests)
iris %>%
  group_by(Species) %>%
  summarize(shapiro_p_value = shapiro.test(Sepal.Length)$p.value)</code></pre>

      <div class="exercise">
        <h3>Exercise: Hypothesis Testing</h3>
        <p>Using the `iris` dataset:</p>
        <p>1. Perform a two-sample t-test to see if the mean `Petal.Width` is significantly different between the `versicolor` and `virginica` species.</p>
        <p>2. Perform a one-way ANOVA to test if the mean `Sepal.Width` differs significantly across the three species.</p>
        <p>3. Check if the `Petal.Length` for the `setosa` species appears to be normally distributed using the Shapiro-Wilk test.</p>
        <button onclick="toggleSolution('sol_hypo_test')">Show/Hide Solution Code</button>
        <div class="result" id="sol_hypo_test" style="display: none; background-color: #f5f5f5;">
            <pre><code>data(iris)
library(dplyr)

# 1. Two-sample t-test for Petal.Width (versicolor vs virginica)
versi_virgi <- subset(iris, Species %in% c("versicolor", "virginica"))
t_test_petal_width <- t.test(Petal.Width ~ Species, data = versi_virgi)
print("T-test Result (Petal.Width: versicolor vs virginica):")
print(t_test_petal_width)
# Interpretation: Check the p-value. A small p-value (< 0.05) suggests a significant difference.

# 2. One-way ANOVA for Sepal.Width across Species
aov_sepal_width <- aov(Sepal.Width ~ Species, data = iris)
print("ANOVA Result (Sepal.Width ~ Species):")
print(summary(aov_sepal_width))
# Interpretation: Check the Pr(>F) value. A small p-value (< 0.05) suggests at least one species
# has a different mean Sepal.Width. You could follow up with TukeyHSD().

# 3. Shapiro-Wilk test for Petal.Length (setosa)
setosa_petal_length <- subset(iris, Species == "setosa")$Petal.Length
shapiro_test_setosa <- shapiro.test(setosa_petal_length)
print("Shapiro-Wilk Test Result (Petal.Length for setosa):")
print(shapiro_test_setosa)
# Interpretation: Check the p-value. If > 0.05, we fail to reject the null hypothesis
# of normality (i.e., it's plausible the data is normally distributed).</code></pre>
        </div>
      </div>
    </div>

    <div class="section" id="linear-regression">
      <h2>Linear Regression</h2>
      <p>Linear regression models the relationship between a continuous dependent variable (outcome) and one or more independent variables (predictors) by fitting a linear equation to the observed data.</p>
      <p>The basic form is: Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + Œ≤‚ÇÇX‚ÇÇ + ... + Œµ</p>
      <ul>
        <li>Y: Dependent variable</li>
        <li>X‚ÇÅ, X‚ÇÇ,...: Independent variables</li>
        <li>Œ≤‚ÇÄ: Intercept (value of Y when all X are 0)</li>
        <li>Œ≤‚ÇÅ, Œ≤‚ÇÇ,...: Coefficients (change in Y for a one-unit change in X, holding others constant)</li>
        <li>Œµ: Error term (variability not explained by the model)</li>
      </ul>

      <h4>Fitting a Linear Model (`lm`)</h4>
      <p>The `lm()` function is used to fit linear models.</p>
      <pre><code># Simple linear regression: Predict mpg from weight (wt) using mtcars
model_simple <- lm(mpg ~ wt, data = mtcars)

# Multiple linear regression: Predict mpg from weight (wt) and horsepower (hp)
model_multiple <- lm(mpg ~ wt + hp, data = mtcars)

# Regression with categorical predictors (R handles dummy coding automatically)
# Predict mpg from weight (wt) and number of cylinders (cyl, treated as factor)
model_factor <- lm(mpg ~ wt + factor(cyl), data = mtcars)</code></pre>

      <h4>Interpreting Model Summary</h4>
      <p>The `summary()` function provides detailed output about the fitted model.</p>
      <pre><code># Get summary of the multiple regression model
summary_multiple <- summary(model_multiple)
print(summary_multiple)</code></pre>
      <p>Key parts of the summary:</p>
      <ul>
        <li><strong>Call:</strong> Shows the formula used.</li>
        <li><strong>Residuals:</strong> Summary statistics of the differences between observed and predicted values. Ideally centered around 0.</li>
        <li><strong>Coefficients:</strong>
          <ul>
            <li>`Estimate`: The calculated values for Œ≤‚ÇÄ, Œ≤‚ÇÅ, etc.</li>
            <li>`Std. Error`: The standard error of the coefficient estimates.</li>
            <li>`t value`: The coefficient estimate divided by its standard error.</li>
            <li>`Pr(>|t|)`: The p-value for the hypothesis test that the true coefficient is 0. Small p-values (< 0.05) suggest the predictor is significantly related to the outcome.</li>
            <li>Signif. codes: Stars indicating significance levels (e.g., *** for p < 0.001).</li>
          </ul>
        </li>
        <li><strong>Residual standard error:</strong> An estimate of the standard deviation of the error term (Œµ).</li>
        <li><strong>R-squared (Multiple R-squared):</strong> The proportion of the variance in the dependent variable that is predictable from the independent variables (ranges from 0 to 1). Higher is generally better.</li>
        <li><strong>Adjusted R-squared:</strong> R-squared adjusted for the number of predictors in the model. More suitable for comparing models with different numbers of predictors.</li>
        <li><strong>F-statistic:</strong> Tests the overall significance of the model (H‚ÇÄ: All coefficients except the intercept are 0). A small p-value suggests the model is statistically significant overall.</li>
      </ul>

      <h4>Checking Model Assumptions</h4>
      <p>Linear regression relies on several assumptions. Violations can invalidate the results. Common checks involve plotting residuals:</p>
      <pre><code># Plot diagnostics for the multiple regression model
par(mfrow = c(2, 2)) # Arrange plots in a 2x2 grid
plot(model_multiple)
par(mfrow = c(1, 1)) # Reset plotting layout</code></pre>
      <p>Key diagnostic plots:</p>
      <ul>
        <li><strong>Residuals vs Fitted:</strong> Checks linearity and equal variance (homoscedasticity). Points should be randomly scattered around the horizontal line at 0, with no clear pattern (like a curve or funnel).</li>
        <li><strong>Normal Q-Q:</strong> Checks if residuals are normally distributed. Points should fall approximately along the diagonal line.</li>
        <li><strong>Scale-Location:</strong> Checks homoscedasticity again. Points should be randomly scattered with roughly constant spread.</li>
        <li><strong>Residuals vs Leverage:</strong> Identifies influential points (outliers in X space that might unduly influence the regression line). Points outside Cook's distance lines might be problematic.</li>
      </ul>

      <h4>Making Predictions</h4>
      <p>Use the `predict()` function to predict outcomes for new data.</p>
      <pre><code># Create new data frame with values for predictors
new_cars <- data.frame(
  wt = c(2.5, 3.0, 3.5),
  hp = c(100, 150, 200)
)

# Predict mpg for the new cars using the multiple regression model
predicted_mpg <- predict(model_multiple, newdata = new_cars)
print(predicted_mpg)

# You can also get confidence or prediction intervals
predict(model_multiple, newdata = new_cars, interval = "confidence") # Interval for the average mpg
predict(model_multiple, newdata = new_cars, interval = "prediction") # Interval for a single new observation</code></pre>

      <div class="exercise">
        <h3>Exercise: Linear Regression</h3>
        <p>Using the `iris` dataset:</p>
        <p>1. Fit a simple linear regression model predicting `Petal.Length` using `Sepal.Length` as the predictor.</p>
        <p>2. Print the summary of the model. Is `Sepal.Length` a significant predictor of `Petal.Length`? What proportion of the variance in `Petal.Length` does the model explain?</p>
        <p>3. Predict the `Petal.Length` for irises with `Sepal.Length` values of 5.0, 6.0, and 7.0.</p>
        <p>4. (Optional) Plot the diagnostic plots for the model.</p>
        <button onclick="toggleSolution('sol_regression')">Show/Hide Solution Code</button>
        <div class="result" id="sol_regression" style="display: none; background-color: #f5f5f5;">
            <pre><code>data(iris)

# 1. Fit the linear model
iris_model <- lm(Petal.Length ~ Sepal.Length, data = iris)

# 2. Print and interpret summary
model_summary <- summary(iris_model)
print(model_summary)

# Interpretation:
# - Significance: Look at the p-value (Pr(>|t|)) for the Sepal.Length coefficient.
#   If it's very small (typically < 0.05), then Sepal.Length is a significant predictor.
# - Variance Explained: Look at the 'Multiple R-squared' value. This represents the
#   proportion of variance explained (e.g., 0.75 means 75% of the variance in
#   Petal.Length is explained by Sepal.Length in this model).

# 3. Predict Petal.Length
new_sepal_lengths <- data.frame(Sepal.Length = c(5.0, 6.0, 7.0))
predicted_petal_lengths <- predict(iris_model, newdata = new_sepal_lengths)
print("Predicted Petal Lengths:")
print(predicted_petal_lengths)

# 4. (Optional) Diagnostic plots
par(mfrow = c(2, 2))
plot(iris_model)
par(mfrow = c(1, 1))</code></pre>
        </div>
      </div>
    </div>

    <div class="section resources">
        <h3>Further Resources</h3>
        <ul>
            <li><a href="https://www.statmethods.net/stats/descriptives.html" target="_blank">Quick-R: Descriptive Statistics</a></li>
            <li><a href="https://www.statmethods.net/stats/correlations.html" target="_blank">Quick-R: Correlations</a></li>
            <li><a href="https://r4ds.had.co.nz/model-basics.html" target="_blank">R for Data Science: Model Basics (Intro to lm)</a></li>
            <li><a href="https://www.statmethods.net/stats/regression.html" target="_blank">Quick-R: Regression</a></li>
            <li><a href="https://www.statmethods.net/stats/ttest.html" target="_blank">Quick-R: t-Tests</a></li>
            <li><a href="https://www.statmethods.net/stats/chisq.html" target="_blank">Quick-R: Chi-Square Tests</a></li>
            <li><a href="https://www.statmethods.net/stats/anova.html" target="_blank">Quick-R: ANOVA</a></li>
            <li><a href="https://data.library.virginia.edu/getting-started-with-hypothesis-testing-in-r/" target="_blank">UVA Library: Getting Started with Hypothesis Testing in R</a></li>
            <li><a href="http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software" target="_blank">STHDA: Correlation Matrix Guide</a></li>
             <li><a href="http://www.sthda.com/english/articles/39-regression-analysis/161-linear-regression-essentials-in-r/" target="_blank">STHDA: Linear Regression Essentials in R</a></li>
        </ul>
    </div>

  </div> <!-- /container -->

  <footer>
    <div class="container">
      <p>HARP Team R Training &copy; 2025 | Created by Daryn Sutton</p>
    </div>
  </footer>

  <script>
    function checkAnswer(questionId, correctAnswer) {
      const selectedOption = document.querySelector(`input[name="${questionId}"]:checked`);
      const resultDiv = document.getElementById(`${questionId}-result`);

      if (!selectedOption) {
        resultDiv.textContent = "Please select an answer.";
        resultDiv.className = "result incorrect";
        resultDiv.style.display = "block";
        return;
      }

      if (selectedOption.value === correctAnswer) {
        resultDiv.textContent = "Correct! Well done.";
        resultDiv.className = "result correct";
      } else {
        resultDiv.textContent = `Incorrect. The correct answer is: ${correctAnswer}`;
        resultDiv.className = "result incorrect";
      }

      resultDiv.style.display = "block";
    }

    // Simple toggle function for solution code blocks
    function toggleSolution(id) {
        var element = document.getElementById(id);
        if (element.style.display === "none") {
            element.style.display = "block";
        } else {
            element.style.display = "none";
        }
    }

    // Placeholder for potential code checking functions if needed later
    function checkCodeExercise(inputId, resultId /*, validationLogic */) {
       const userCode = document.getElementById(inputId).value.trim();
       const resultDiv = document.getElementById(resultId);
       // Basic feedback for now
       if (userCode) {
           resultDiv.textContent = "Code submitted (validation logic not implemented in this example).";
           resultDiv.className = "result correct"; // Assume correct for demo
       } else {
           resultDiv.textContent = "Please enter some code.";
           resultDiv.className = "result incorrect";
       }
       resultDiv.style.display = "block";
    }
  </script>
</body>
</html>
